{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ayi00KQngCv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "glo64_l2-4   | CV macro-F1 = 0.9749 ± 0.0087\n",
            "glo64_l2-3   | CV macro-F1 = 0.9756 ± 0.0058\n",
            "norm64_l2-4  | CV macro-F1 = 0.9714 ± 0.0068\n",
            "heDeep_l2-4  | CV macro-F1 = 0.9722 ± 0.0100\n",
            "heDeep_l2-3  | CV macro-F1 = 0.9736 ± 0.0095\n",
            "norm128_l2-3 | CV macro-F1 = 0.9771 ± 0.0084\n",
            "he64_l2-2    | CV macro-F1 = 0.9728 ± 0.0098\n",
            "glo256_128_64_l2-1 | CV macro-F1 = 0.9736 ± 0.0117\n",
            "he256_16_l2-3 | CV macro-F1 = 0.9777 ± 0.0053\n",
            "glo32_128_64_l2-5 | CV macro-F1 = 0.9784 ± 0.0067\n",
            "norm128_64_32_l2-1 | CV macro-F1 = 0.9791 ± 0.0049\n",
            "he128_64_l2-2 | CV macro-F1 = 0.9791 ± 0.0072\n",
            "norm256_l2-4 | CV macro-F1 = 0.9798 ± 0.0086\n",
            "glo32x4_l2-0 | CV macro-F1 = 0.9771 ± 0.0074\n",
            "\n",
            ">> Selecionado: norm256_l2-4 {'layers': (256,), 'alpha': 0.0001, 'weight_init': 'normal', 'activation': 'logistic'}\n",
            "\n",
            ">> TESTE | acc = 0.95556 | macro-F1 = 0.95473\n",
            "\n",
            "Resumo completo:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>config</th>\n",
              "      <th>layers</th>\n",
              "      <th>alpha</th>\n",
              "      <th>init</th>\n",
              "      <th>acc_mean</th>\n",
              "      <th>acc_std</th>\n",
              "      <th>f1_mean</th>\n",
              "      <th>f1_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>norm256_l2-4</td>\n",
              "      <td>(256,)</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>normal</td>\n",
              "      <td>0.979815</td>\n",
              "      <td>0.008648</td>\n",
              "      <td>0.979797</td>\n",
              "      <td>0.008625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>he128_64_l2-2</td>\n",
              "      <td>(128, 64)</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>he_uniform</td>\n",
              "      <td>0.979123</td>\n",
              "      <td>0.007300</td>\n",
              "      <td>0.979127</td>\n",
              "      <td>0.007226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>norm128_64_32_l2-1</td>\n",
              "      <td>(128, 64, 32)</td>\n",
              "      <td>0.10000</td>\n",
              "      <td>normal</td>\n",
              "      <td>0.979123</td>\n",
              "      <td>0.004924</td>\n",
              "      <td>0.979077</td>\n",
              "      <td>0.004930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>glo32_128_64_l2-5</td>\n",
              "      <td>(32, 128, 64)</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>glorot</td>\n",
              "      <td>0.978426</td>\n",
              "      <td>0.006759</td>\n",
              "      <td>0.978419</td>\n",
              "      <td>0.006735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>he256_16_l2-3</td>\n",
              "      <td>(256, 16)</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>he_uniform</td>\n",
              "      <td>0.977734</td>\n",
              "      <td>0.005198</td>\n",
              "      <td>0.977652</td>\n",
              "      <td>0.005265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>glo32x4_l2-0</td>\n",
              "      <td>(32, 32, 32, 32)</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>glorot</td>\n",
              "      <td>0.977037</td>\n",
              "      <td>0.007497</td>\n",
              "      <td>0.977095</td>\n",
              "      <td>0.007447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>norm128_l2-3</td>\n",
              "      <td>(128,)</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>normal</td>\n",
              "      <td>0.977040</td>\n",
              "      <td>0.008394</td>\n",
              "      <td>0.977091</td>\n",
              "      <td>0.008362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>glo64_l2-3</td>\n",
              "      <td>(64,)</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>glorot</td>\n",
              "      <td>0.975644</td>\n",
              "      <td>0.005831</td>\n",
              "      <td>0.975572</td>\n",
              "      <td>0.005797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>glo64_l2-4</td>\n",
              "      <td>(64,)</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>glorot</td>\n",
              "      <td>0.974940</td>\n",
              "      <td>0.008666</td>\n",
              "      <td>0.974929</td>\n",
              "      <td>0.008686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>glo256_128_64_l2-1</td>\n",
              "      <td>(256, 128, 64)</td>\n",
              "      <td>0.10000</td>\n",
              "      <td>glorot</td>\n",
              "      <td>0.973553</td>\n",
              "      <td>0.011790</td>\n",
              "      <td>0.973609</td>\n",
              "      <td>0.011749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>heDeep_l2-3</td>\n",
              "      <td>(128, 64)</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>he_uniform</td>\n",
              "      <td>0.973558</td>\n",
              "      <td>0.009497</td>\n",
              "      <td>0.973566</td>\n",
              "      <td>0.009471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>he64_l2-2</td>\n",
              "      <td>(64,)</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>he_uniform</td>\n",
              "      <td>0.972859</td>\n",
              "      <td>0.009710</td>\n",
              "      <td>0.972827</td>\n",
              "      <td>0.009774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>heDeep_l2-4</td>\n",
              "      <td>(128, 64)</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>he_uniform</td>\n",
              "      <td>0.972162</td>\n",
              "      <td>0.010104</td>\n",
              "      <td>0.972203</td>\n",
              "      <td>0.009990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>norm64_l2-4</td>\n",
              "      <td>(64,)</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>normal</td>\n",
              "      <td>0.971472</td>\n",
              "      <td>0.006739</td>\n",
              "      <td>0.971430</td>\n",
              "      <td>0.006773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                config            layers    alpha        init  acc_mean  \\\n",
              "12        norm256_l2-4            (256,)  0.00010      normal  0.979815   \n",
              "11       he128_64_l2-2         (128, 64)  0.01000  he_uniform  0.979123   \n",
              "10  norm128_64_32_l2-1     (128, 64, 32)  0.10000      normal  0.979123   \n",
              "9    glo32_128_64_l2-5     (32, 128, 64)  0.00001      glorot  0.978426   \n",
              "8        he256_16_l2-3         (256, 16)  0.00100  he_uniform  0.977734   \n",
              "13        glo32x4_l2-0  (32, 32, 32, 32)  1.00000      glorot  0.977037   \n",
              "5         norm128_l2-3            (128,)  0.00100      normal  0.977040   \n",
              "1           glo64_l2-3             (64,)  0.00100      glorot  0.975644   \n",
              "0           glo64_l2-4             (64,)  0.00010      glorot  0.974940   \n",
              "7   glo256_128_64_l2-1    (256, 128, 64)  0.10000      glorot  0.973553   \n",
              "4          heDeep_l2-3         (128, 64)  0.00100  he_uniform  0.973558   \n",
              "6            he64_l2-2             (64,)  0.01000  he_uniform  0.972859   \n",
              "3          heDeep_l2-4         (128, 64)  0.00010  he_uniform  0.972162   \n",
              "2          norm64_l2-4             (64,)  0.00010      normal  0.971472   \n",
              "\n",
              "     acc_std   f1_mean    f1_std  \n",
              "12  0.008648  0.979797  0.008625  \n",
              "11  0.007300  0.979127  0.007226  \n",
              "10  0.004924  0.979077  0.004930  \n",
              "9   0.006759  0.978419  0.006735  \n",
              "8   0.005198  0.977652  0.005265  \n",
              "13  0.007497  0.977095  0.007447  \n",
              "5   0.008394  0.977091  0.008362  \n",
              "1   0.005831  0.975572  0.005797  \n",
              "0   0.008666  0.974929  0.008686  \n",
              "7   0.011790  0.973609  0.011749  \n",
              "4   0.009497  0.973566  0.009471  \n",
              "6   0.009710  0.972827  0.009774  \n",
              "3   0.010104  0.972203  0.009990  \n",
              "2   0.006739  0.971430  0.006773  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --------------------------------------------------\n",
        "# 0. Pacotes\n",
        "# --------------------------------------------------\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import (train_test_split,\n",
        "                                     StratifiedKFold,\n",
        "                                     cross_validate)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (accuracy_score,\n",
        "                             f1_score,\n",
        "                             make_scorer)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. Wrapper: MLP com escolha de inicialização\n",
        "# --------------------------------------------------\n",
        "class InitMLP(MLPClassifier):\n",
        "    \"\"\"\n",
        "    MLPClassifier com escolha da estratégia de inicialização:\n",
        "    'glorot' (padrão), 'normal' ou 'he_uniform'.\n",
        "    \"\"\"\n",
        "    def __init__(self, *,              # força kwargs-only\n",
        "                 weight_init=\"glorot\",  # novo parâmetro\n",
        "                 **kwargs):             # passa o resto para o MLP original\n",
        "        super().__init__(**kwargs)\n",
        "        self.weight_init = weight_init\n",
        "\n",
        "    # --- substitui os pesos depois da _initialize do pai ---\n",
        "    def _initialize(self, y, layer_units, dtype):\n",
        "        super()._initialize(y, layer_units, dtype)\n",
        "        rng = self._random_state\n",
        "        for i, (fan_in, fan_out) in enumerate(zip(layer_units[:-1],\n",
        "                                                  layer_units[1:])):\n",
        "            shape = (fan_in, fan_out)\n",
        "            if self.weight_init == \"normal\":\n",
        "                scale = 1. / np.sqrt(fan_in)\n",
        "                self.coefs_[i] = rng.normal(0.0, scale, size=shape)\n",
        "            elif self.weight_init == \"he_uniform\":\n",
        "                limit = np.sqrt(6. / fan_in)\n",
        "                self.coefs_[i] = rng.uniform(-limit, limit, size=shape)\n",
        "            # ‘glorot’ já foi gerado pelo método do pai\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. Dados\n",
        "# --------------------------------------------------\n",
        "X, y = load_digits(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=42)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3. Configurações (arquitetura, L2, inicialização)\n",
        "# --------------------------------------------------\n",
        "\n",
        "# Escopo de configs considerado para as arquiteturas:\n",
        "# 1 a 4 camadas\n",
        "# 16 a 256 camadas\n",
        "# alpha: 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5\n",
        "# inicialização: 'glorot', 'normal', 'he_uniform'\n",
        "# ativation: 'relu', 'logistic', 'tanh' (padrão é 'relu')\n",
        "configs = {\n",
        "    #  nome        layers                   alpha       init\n",
        "    \"glo64_l2-4\": dict(layers=(64,),       alpha=1e-4, weight_init=\"glorot\"),\n",
        "    \"glo64_l2-3\": dict(layers=(64,),       alpha=1e-3, weight_init=\"glorot\"),\n",
        "    \"norm64_l2-4\":dict(layers=(64,),       alpha=1e-4, weight_init=\"normal\"),\n",
        "    \"heDeep_l2-4\":dict(layers=(128, 64),   alpha=1e-4, weight_init=\"he_uniform\"),\n",
        "    \"heDeep_l2-3\":dict(layers=(128, 64),   alpha=1e-3, weight_init=\"he_uniform\"),\n",
        "    ## ... adicione mais 5 ou mais combinacoes ...\n",
        "    # \"reluWide_l2-2\": dict(layers=(n,n),\n",
        "    #                   alpha=1e-2,\n",
        "    #                   weight_init=\"he_uniform\",\n",
        "    #                   activation=\"relu\")\n",
        "    \"norm128_l2-3\": dict(layers=(128,), alpha=1e-3, weight_init=\"normal\", activation=\"relu\"),\n",
        "    \"he64_l2-2\":    dict(layers=(64,),  alpha=1e-2, weight_init=\"he_uniform\", activation=\"logistic\"),\n",
        "    \"glo256_128_64_l2-1\": dict(layers=(256, 128, 64), alpha=1e-1, weight_init=\"glorot\", activation=\"tanh\"),\n",
        "    \"he256_16_l2-3\":  dict(layers=(256, 16), alpha=1e-3, weight_init=\"he_uniform\", activation=\"relu\"),\n",
        "    \"glo32_128_64_l2-5\": dict(layers=(32, 128, 64), alpha=1e-5, weight_init=\"glorot\", activation=\"logistic\"),\n",
        "    \"norm128_64_32_l2-1\": dict(layers=(128, 64, 32), alpha=1e-1, weight_init=\"normal\", activation=\"tanh\"),\n",
        "    \"he128_64_l2-2\":   dict(layers=(128, 64), alpha=1e-2, weight_init=\"he_uniform\", activation=\"relu\"),\n",
        "    \"norm256_l2-4\": dict(layers=(256,), alpha=1e-4, weight_init=\"normal\", activation=\"logistic\"),\n",
        "    \"glo32x4_l2-0\":      dict(layers=(32, 32, 32, 32), alpha=1, weight_init=\"glorot\", activation=\"relu\")\n",
        "}\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 4. Validação cruzada no treino\n",
        "# --------------------------------------------------\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = {\"acc\": \"accuracy\",\n",
        "           \"f1\":  make_scorer(f1_score, average=\"macro\")}\n",
        "\n",
        "rows = []\n",
        "for name, p in configs.items():\n",
        "    clf = InitMLP(\n",
        "        hidden_layer_sizes=p[\"layers\"],\n",
        "        alpha=p[\"alpha\"],\n",
        "        weight_init=p[\"weight_init\"],\n",
        "        max_iter=200,\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=5,\n",
        "        learning_rate_init=1e-3,\n",
        "        solver=\"adam\",\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "\n",
        "    pipe = Pipeline([(\"scale\", StandardScaler()),\n",
        "                     (\"clf\",   clf)])\n",
        "\n",
        "    res = cross_validate(pipe, X_train, y_train,\n",
        "                         cv=cv, scoring=scoring,\n",
        "                         return_train_score=False)\n",
        "\n",
        "    rows.append({\n",
        "        \"config\":   name,\n",
        "        \"layers\":   p[\"layers\"],\n",
        "        \"alpha\":    p[\"alpha\"],\n",
        "        \"init\":     p[\"weight_init\"],\n",
        "        \"f1_mean\":  res[\"test_f1\"].mean(),\n",
        "        \"f1_std\":   res[\"test_f1\"].std(),\n",
        "        \"acc_mean\": res[\"test_acc\"].mean(),\n",
        "        \"acc_std\":  res[\"test_acc\"].std(),\n",
        "    })\n",
        "\n",
        "    print(f\"{name:12s} | CV macro-F1 = \"\n",
        "          f\"{res['test_f1'].mean():.4f} ± {res['test_f1'].std():.4f}\")\n",
        "\n",
        "summary = (pd.DataFrame(rows)\n",
        "              .sort_values(\"f1_mean\", ascending=False))\n",
        "\n",
        "best_conf  = summary.iloc[0]\n",
        "best_name  = best_conf[\"config\"]\n",
        "best_param = configs[best_name]\n",
        "print(\"\\n>> Selecionado:\", best_name, dict(best_param))\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 5. Re-treino em todo o treino + teste final\n",
        "# --------------------------------------------------\n",
        "best_clf = InitMLP(\n",
        "    hidden_layer_sizes=best_param[\"layers\"],\n",
        "    alpha=best_param[\"alpha\"],\n",
        "    weight_init=best_param[\"weight_init\"],\n",
        "    max_iter=200,\n",
        "    early_stopping=True,\n",
        "    n_iter_no_change=5,\n",
        "    learning_rate_init=1e-3,\n",
        "    solver=\"adam\",\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "best_pipe = Pipeline([(\"scale\", StandardScaler()),\n",
        "                      (\"clf\",   best_clf)])\n",
        "best_pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred   = best_pipe.predict(X_test)\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "test_f1  = f1_score(y_test, y_pred, average=\"macro\")\n",
        "\n",
        "print(f\"\\n>> TESTE | acc = {test_acc:.5f} | macro-F1 = {test_f1:.5f}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 6. Tabela resumo (para o relatório)\n",
        "# --------------------------------------------------\n",
        "print(\"\\nResumo completo:\")\n",
        "display(summary[[\"config\", \"layers\", \"alpha\", \"init\",\n",
        "                 \"acc_mean\", \"acc_std\", \"f1_mean\", \"f1_std\"]])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
